ğŸ¬ Proyecto Final â€“ IngenierÃ­a de Datos con Databricks

Arquitectura Medallion | PySpark | Azure Databricks | GitHub

ğŸ“Œ DescripciÃ³n general

Este proyecto implementa un pipeline ETL completo en Azure Databricks, utilizando PySpark y siguiendo la arquitectura Medallion (Raw, Bronze, Silver, Gold).
El objetivo es ingestar, transformar y modelar datos provenientes de mÃºltiples datasets relacionados con pelÃ­culas, dejÃ¡ndolos listos para anÃ¡lisis y visualizaciÃ³n.

El proyecto cumple con todas las condiciones establecidas en el enunciado del trabajo final del curso de IngenierÃ­a de Datos con Databricks.

ğŸ¯ Objetivos del proyecto

Implementar un ETL usando PySpark

Aplicar la arquitectura Medallion

Utilizar Azure Data Lake Gen2 como almacenamiento

Conectarse a la capa Raw usando Managed Identity

Integrar mÃºltiples datasets

Orquestar el pipeline usando Databricks Workflows (Job YAML)

Versionar el cÃ³digo en GitHub

Dejar los datos listos para consumo analÃ­tico

ğŸ§± Arquitectura Medallion
RAW (ADLS Gen2)
   â†“
BRONZE (Datos limpios)
   â†“
SILVER (Datos integrados y con reglas de negocio)
   â†“
GOLD (Modelo analÃ­tico)

Capas:
ğŸ”¹ RAW

Ingesta de archivos CSV desde ADLS Gen2

Sin transformaciones

Datos almacenados en formato Parquet

Acceso usando Managed Identity

No se utiliza DBFS ni Volumes

ğŸ”¹ BRONZE

NormalizaciÃ³n de nombres de columnas

EliminaciÃ³n de duplicados

ConversiÃ³n bÃ¡sica de tipos

Datos confiables pero sin lÃ³gica de negocio

ğŸ”¹ SILVER

IntegraciÃ³n de mÃºltiples datasets

Joins por identificador de pelÃ­cula

AplicaciÃ³n de reglas de negocio

Dataset unificado y consistente

ğŸ”¹ GOLD

CreaciÃ³n de datasets analÃ­ticos

Agregaciones y mÃ©tricas

Datos listos para visualizaciÃ³n y BI

ğŸ“‚ Datasets utilizados

Se utilizaron mÃºltiples datasets pÃºblicos (Kaggle) relacionados con pelÃ­culas:

Movies.csv

FilmDetails.csv

MoreInfo.csv

PosterPath.csv

Estos datasets permiten cumplir con el requisito de mÃ­nimo dos insumos para el ETL.

ğŸ—‚ï¸ Estructura del repositorio
databricks-movies-project/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ingest_raw_movies
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â””â”€â”€ bronze_movies
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â””â”€â”€ silver_movies
â”‚   â””â”€â”€ gold/
â”‚       â””â”€â”€ gold_movies_analytics
â”‚
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ movies_etl_job.yml
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dev.yml
â”‚   â””â”€â”€ prod.yml
â”‚
â””â”€â”€ README.md

âš™ï¸ TecnologÃ­as utilizadas

Azure Databricks

PySpark

Azure Data Lake Storage Gen2

Managed Identity

Databricks Workflows (Jobs)

GitHub

ğŸ” Seguridad y acceso

El acceso al Data Lake se realiza exclusivamente mediante Managed Identity

No se utilizan:

Storage keys

Secrets

DBFS

Volumes como capa Raw

Esto garantiza buenas prÃ¡cticas de seguridad y cumplimiento del enunciado.

ğŸ” OrquestaciÃ³n del pipeline

El pipeline se orquesta usando un Databricks Job definido en YAML, que ejecuta las capas en el siguiente orden:

RAW â€“ Ingesta

BRONZE â€“ Limpieza

SILVER â€“ IntegraciÃ³n

GOLD â€“ AnalÃ­tica

El orden estÃ¡ controlado mediante dependencias entre tareas (depends_on).

ğŸ“Š Resultados â€“ Capa GOLD

La capa GOLD genera datasets analÃ­ticos como:

MÃ©tricas generales de pelÃ­culas (KPI)

PelÃ­culas por gÃ©nero

Top pelÃ­culas por rating

PelÃ­culas por aÃ±o de lanzamiento

Estos datasets estÃ¡n listos para ser consumidos por:

Databricks SQL

Power BI

Herramientas de BI externas

ğŸš€ EjecuciÃ³n del proyecto
OpciÃ³n 1 â€“ Desde Databricks

Importar el Job YAML

Asignar un cluster existente

Ejecutar el workflow completo

OpciÃ³n 2 â€“ Desde GitHub

El cÃ³digo se encuentra versionado

El pipeline puede integrarse a procesos de CI/CD

âœ… Cumplimiento de requisitos del proyecto
Requisito	Cumple
Arquitectura Medallion	âœ…
PySpark	âœ…
â‰¥ 2 datasets	âœ…
Managed Identity	âœ…
No DBFS / Volumes en Raw	âœ…
ETL completo	âœ…
YAML de orquestaciÃ³n	âœ…
GitHub	âœ…
ğŸ“Œ ConclusiÃ³n

Este proyecto demuestra la aplicaciÃ³n prÃ¡ctica de conceptos clave de IngenierÃ­a de Datos, incluyendo:

DiseÃ±o de pipelines ETL

Buenas prÃ¡cticas de seguridad

Arquitectura Medallion

OrquestaciÃ³n en Databricks

PreparaciÃ³n de datos para analÃ­tica

El resultado es un pipeline robusto, escalable y alineado con estÃ¡ndares reales de la industria.